{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline prep\n",
    "This notebook will log the creation process for the Toronto Building Permits ELT data pipeline. First we take inventory of sources and transformations required to generate the gold table of permits summaries per neighbourhood on a monthly basis. Next we will choose then connect to a database service to host the db we will connect to with our data pipeline framework. We will be using `dbt` as our framework for our data pipeline. Finally we will create our transformations and implement tests to ensure data QA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data inventory\n",
    "From our exploratory data analysis, we have generated the following data flow in developing our data:\n",
    "\n",
    "**Source (Bronze) Data:**\n",
    "- Building Permits Data, Cleared `BPC`\n",
    "- Building Permits Data, Active `BPA`\n",
    "- Municipal Address Points `AP`\n",
    "- Neighbourhoods `N`\n",
    "\n",
    "**Silver Data**\n",
    "- Building Permits Data, processed and annotated `BP`\n",
    "- Addresses by Neighbourhoods `AN`\n",
    "\n",
    "**Gold Data**\n",
    "- Neighbiourhoods by Month `NBM`\n",
    "\n",
    "**Transformations (Mermaid)**\n",
    "\n",
    "![mermaid code for flowchart in following cell](diagrams/bp-flow-original.svg \"a title\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart TB\n",
    "\n",
    "%% STAGE 1: Concat and prepare building permits\n",
    "\n",
    "    bpa1[BPA] ---h1([\"`hash:\n",
    "        'PERMIT_NUM', \n",
    "        'REVISION_NUM', \n",
    "        'PERMIT_TYPE', \n",
    "        'BUILDER_NAME'`\"]) \n",
    "        -->bpa2[BPA]\n",
    "    bpc1[BPC] ---h2([\"`hash:\n",
    "        'PERMIT_NUM', \n",
    "        'REVISION_NUM', \n",
    "        'PERMIT_TYPE', \n",
    "        'BUILDER_NAME'`\"]) \n",
    "        -->bpc2[BPC]\n",
    "    bpa2 & bpc2 ---c1([concat]) -->bp1[BP]\n",
    "    \n",
    "    bp1 ---f1([filter by permit type and status])\n",
    "        ---ed1([add effective date])\n",
    "        ---s3([\"`SELECT\n",
    "        _GEO_ID,\n",
    "        effective_date,\n",
    "        EST_CONST_COST_`\"])\n",
    "        -->bp2[BP]\n",
    "\n",
    "%% STAGE 2: Geofence properties into neighbourhoods\n",
    "        \n",
    "    ap1[AP] ---s1([\"`SELECT\n",
    "        _ADDRESS_POINT_ID, \n",
    "        geometry_`\"])\n",
    "        ---pg1([parse geometry])\n",
    "        -->ap2[AP]\n",
    "\n",
    "    n1[N] ---s2([\"`SELECT\n",
    "        _AREA_ID,\n",
    "        AREA_SHORT_CODE,\n",
    "        AREA_NAME, \n",
    "        geometry_`\"])\n",
    "        -->pg2([parse geometry])\n",
    "        -->n2[N]\n",
    "    \n",
    "    ap2 & n2 ---gpd1([\"`geopandas overlay\n",
    "        (intersection):\n",
    "        _ADDRESS_POINT_ID \n",
    "        to AREA_ID_`\"])\n",
    "        -->an1[AN]\n",
    "\n",
    "%% STAGE 3: Join neighbourhoods to permits (Possible split here)\n",
    "    \n",
    "    bp2 & an1 ---lj([\"`left join: \n",
    "        _GEO_ID to \n",
    "        ADDRESS_POINT_ID_`\"])\n",
    "        --> bp3[BP]\n",
    "\n",
    "%% STAGE 4: Group and summarise by interval (month)\n",
    "\n",
    "    bp3 ---cd1([convert dates to datetime])\n",
    "        ---am1([add month column])\n",
    "        ---gb1([\"`group by \n",
    "        _AREA_NAME, month_`\"])\n",
    "        ---sm1([\"`summarise:\n",
    "        sum(EST_CONST_COST),\n",
    "        count(GEO_ID)\n",
    "        `\"])\n",
    "        -->nbm1[NBM]\n",
    "\n",
    "%% STAGE 5: Add total properties per neighbourhood\n",
    "\n",
    "    an1 ---gb2([\"`group by\n",
    "        _AREA NAME_`\"])\n",
    "        ---sm2([\"`summarise:\n",
    "        unique(ADDRESS_POINT_ID)\n",
    "        `\"])\n",
    "        -->nc1[NC]\n",
    "    \n",
    "    nbm1 & nc1 ---lj2([\"`left join:\n",
    "        on _AREA_NAME_`\"])\n",
    "        -->nbm2[NBM]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing transformations\n",
    "There are several optimizations we can carry out throughout the pipeline\n",
    "\n",
    "### Connecting to data\n",
    "1. We can download data using queries from the CKAN portals. By restricting our API downloads to the columns we use, we can use less storage space on our databases. If we make this configurable we can turn on and off data columns as needed. Here are the columns we need for each source table:\n",
    "\n",
    "**BPA:**\n",
    "\n",
    "`'PERMIT_NUM', 'GEO_ID', 'REVISION_NUM', 'PERMIT_TYPE', 'STATUS', 'BUILDER_NAME', 'APPLICATION_DATE', 'ISSUED_DATE', 'COMPLETED_DATE', 'EST_CONST_COST'`\n",
    "\n",
    "**BPC:**\n",
    "\n",
    "`'PERMIT_NUM', 'GEO_ID', 'REVISION_NUM', 'PERMIT_TYPE', 'STATUS', 'BUILDER_NAME', 'APPLICATION_DATE', 'ISSUED_DATE', 'COMPLETED_DATE', 'EST_CONST_COST'`\n",
    "\n",
    "**AP:**\n",
    "\n",
    "`'ADDRESS_POINT_ID', 'geometry'`\n",
    "\n",
    "**N:**\n",
    "\n",
    "`'AREA_ID', 'AREA_SHORT_CODE', 'AREA_NAME', 'geometry'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
